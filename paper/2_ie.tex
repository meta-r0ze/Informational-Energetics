\section{Theoretical Context: Informational Energetics}
\label{sec:IE}

Any system that persists, from a biological cell to the universe itself, must solve the same fundamental problem: how to maintain structural coherence against the constant pressure of environmental entropy.

Informational Energetics (IE) is a theoretical framework designed to derive the universal architecture required to solve this problem. It unifies insights from non-equilibrium thermodynamics, algorithmic information theory, and robust control theory into a single, predictive model of persistence.

\subsection{The Selection Principle}

The foundational premise of IE is not teleological but \textbf{selectionist}: configurations that fail to persist leave no trace, while configurations that persist constitute the observable universe. This is not a statement about what systems ``want,'' but about what remains after entropic selection.

We formalize this as the \textbf{Persistence Filter}:

\begin{mdframed}[linewidth=1pt,linecolor=black,backgroundcolor=gray!10]
    \textbf{Selection Principle}: Among all possible configurations, only those that minimize \textbf{Entropic Action} ($S_\Phi$) relative to structural complexity remain observable. The Persistence Value ($P$) quantifies this selection: $P \propto 1/S_\Phi$.
\end{mdframed}

This can be viewed as a generalization of the Anthropic Principle, shifting the focus from the conditions required for observers to the more fundamental conditions required for any structure to exist at all, whether observed or not.

While open systems (such as biological organisms) persist by maintaining a non-equilibrium steady state through the continuous flux of energy and matter from their environment, for a closed system persistence operates as a filter: configurations minimize entropic action or dissolve, as there is no external energy source to offset dissipation.

\subsection{The Universal Architecture: Derivation from First Principles}
\label{sec:PillarDerivation}

To persist, any system must implement a specific architecture comprising four pillars for information management and two pillars for the thermodynamic overhead of operating on its substrate.

To rigorously derive this architecture, we model a persistent entity not as a static object, but as a \textbf{dynamic control system} that must regulate its internal state against external fluctuations (entropy). The stability of any such system is governed by a well-defined set of mathematical requirements (e.g., Lyapunov stability, Nyquist criterion).

\subsubsection{The Necessary Components of Control}

From robust control theory, any stable feedback loop requires four functional components \cite{dorf_modern_2017}: the Plant (the system to be controlled), the Sensor (measuring the output), the Controller (computing the correction), and the Actuator (implementing the correction). The desired behavior is specified by a Reference Signal (Setpoint).

For \textit{robust} operation under uncertainty, control systems must additionally implement gain and phase margins to prevent instability from perturbations \cite{astrom_feedback_2008}. These margins are typically treated as tunable parameters rather than structural requirements.

Implicit in physical implementations, but typically treated as a constraint rather than a component, is the Toll: the irreducible energetic and temporal cost of state transitions. (Landauer's Principle \cite{landauer_irreversibility_1961}; Margolus-Levitin limit \cite{margolus_maximum_1998}).

IE reframes these elements into six existential pillars, the complete, minimal set required for persistence. The removal of any pillar leads to catastrophic system failure (\cref{sec:proof_of_necessity}).

\subsubsection{The IE Reframing: From Performance to Persistence}
Traditional Control Theory, though rooted in information theory and thermodynamics, primarily identifies the functional components required for stability and performance. It typically treats the components of the control loop (the Plant, the Setpoint) as mathematical abstractions. 

\textbf{The contribution of IE is to recontextualize these components as existential requirements and unify them within a predictive, quantitative model of persistence.} Performance comes secondary to persistence. Thermodynamic and information-theoretic imperatives are elevated, necessitating terms that reflect a new primary unit of measure: \textbf{Entropic Burden}.

\subsubsection{The Universal Architecture of Persistence}
To facilitate this translation between engineering and ontology, we define the Six Pillars of Persistence not as arbitrary design choices, but as the universal architectural requirements for any entity that successfully resists entropic decay. The mapping from control components to IE pillars is structural: each control function translates to an existential requirement when recontextualized as persistence rather than performance.

\begin{enumerate}
    \item \textbf{The Capacity ($CAP$):} \textit{The Vessel.} 
    The physical infrastructure required to acquire resources, process energy, and perform work. It defines the system's kinetic potential and its ability to act on the environment. (The Plant/Actuator).

    \item \textbf{The Map ($MAP$):} \textit{The Model.}
    The internal logic, topological structure, or compressed representation of environmental regularities that distinguishes the system from the environment. It functions as a predictive engine that reduces uncertainty (Surprisal), allowing the system to steer towards high-utility states. (The Reference Signal/Setpoint).

    \item \textbf{The Protocol ($PRO$):} \textit{The Interface.}
    The communicative glue regulating information flow between the Capacity and the Map. It ensures internal coherence, standardizes interfaces, and minimizes signal decay across the system's internal boundaries. (The Feedback Network/Sensor Path).
    
    \item \textbf{The Governor ($GOV$):} \textit{The Constraint.}
    The non-linear constraint mechanism that prevents unbounded divergence or 'runaway' loops. It enforces operational boundaries (e.g., apoptosis, budget limits) to protect the substrate from exhaustion. (Controller/Limiter).
    
    \item \textbf{The Toll ($TOL$):} \textit{The Temporal Cost.}
    The irreducible energy cost of state transitions and information erasure (Landauerâ€™s Limit). (Processing Latency)
   
    \item \textbf{The Margin ($MAR$):} \textit{The Buffer.}
    The structural and energetic reserves held to absorb stochastic shocks. It defines the system's 'Safe Operating Area,' providing the buffer required to survive environmental variance without terminal failure. (The gain and phase margin)
\end{enumerate}

Every system operates upon a \textbf{Substrate}: the physical medium imposing the immutable limits (bandwidth, latency, noise floor) within which the six pillars must function.

IE reframes control systems not as rigid instruction-following, but as active, energetic defense of identity. While a simple instruction (Open-Loop) dictates a path without regard for the environment, a control system (Closed-Loop) possesses the agency of persistence. It does not just ``do''; it ``remains.'' From a stochastic perspective, this `agency' is a \textbf{structural filter}: in a high-entropy environment, only those configurations that implement this 6-pillar feedback architecture possess the stability required to be observable across cosmic timescales.

The mapping of IE to specific physical domains is inherently adaptive. While the present work \textit{demonstrates} this on the fundamental substrate of the vacuum, the IE framework states that all systems that persist are specific solutions to this same universal architecture. If validated, IE would serve as a \textbf{Rosetta Stone}, establishing that the laws governing a vacuum, a biological cell, or a computational network are specific instances of the same architectural principles.

\subsubsection{The Entropic Balance Sheet}

To quantify persistence, we distinguish between components that consume resources (Structural Burdens) and components that reduce dissipation (Organizational Efficiencies). 
\begin{itemize}
    \item \textbf{Structural Costs ($+$):} The energetic overhead of existence. This includes maintaining boundaries (CAP, MAR), storing internal models (MAP), and the irreversible cost of state updates (TOL). These terms increase the impedance.

    \item \textbf{Organizational Gains ($-$):} The reduction in dissipation achieved through coordination. The Protocol (PRO) minimizes friction by standardizing interfaces; in control theory, this is analogous to the negative feedback signal subtracted from the setpoint ($\epsilon = R - F$). The Governor (GOV) prevents wasteful divergence. These represent structural optimizations: the measurable difference in dissipation between a disorganized system and an organized one.
\end{itemize}
    
The \textbf{Net Entropic Impedance} ($Z_{IE}$) is the algebraic sum of these contributions:

\begin{equation}
\begin{split}
    Z_{IE} &= \underbrace{(CAP + MAP + TOL + MAR)}_{\text{Structural Costs}} \\
           &- \underbrace{(PRO + GOV)}_{\text{Organizational Gains}}
\end{split}
\end{equation}

\subsection{Proof of Necessity: The Failure Modes}
\label{sec:proof_of_necessity}

We demonstrate the necessity of the set $\mathbb{P}$ = $\{CAP,$ $MAP$, $PRO$, $GOV$, $TOL$, $MAR\}$ by analyzing the \textbf{Counterfactual Failure Mode} of a system $S$ where exactly one pillar is removed ($S' = \mathbb{P} \setminus \{x\}$). In every case, the expected lifetime of the system $\tau$ tends to zero.

\begin{itemize}
    \item \textbf{No Capacity ($CAP \to 0$):} The \textit{Starvation Mode}. The system detects threats but lacks the energy to counter them. ($\tau \to 0$ via Equilibrium).
    \item \textbf{No Map ($MAP \to 0$):} The \textit{Dissolution Mode}. The system lacks a reference signal (self-definition), causing the actuator to fire randomly and maximizing internal entropy. ($\tau \to 0$ via loss of boundary).
    \item \textbf{No Protocol ($PRO \to 0$):} The \textit{Decoherence Mode}. The Plant and Controller become statistically independent; commands are based on outdated states. ($\tau \to 0$ via Fragmentation).
    \item \textbf{No Governor ($GOV \to 0$):} The \textit{Divergence Mode}. Positive feedback loops amplify fluctuations without constraint, exceeding structural limits. ($\tau \to 0$ via Explosion).
    \item \textbf{No Toll ($TOL \to 0$):} The \textit{Zeno Mode} (after Zeno's paradox of infinite subdivision). Instantaneous updates ($TOL \to 0$) result in a \textbf{Logical Singularity}. Information processing requires state transitions. A transition time of zero ($TOL \to 0$) implies infinite processing bandwidth; by the Shannon-Hartley theorem, this would require infinite signal power ($C \to \infty$), explicitly violating the \textbf{Finiteness} pillar. Physically, this is bounded by the Margolus-Levitin limit \cite{margolus_maximum_1998}, which establishes that the time $\Delta t$ required to transition between orthogonal states satisfies $\Delta t \ge \frac{h}{4\Delta E}$. A zero-cost transition collapses the distinction between cause and effect, rendering the state space non-computable ($\tau \to 0$ via \textbf{Causal Collapse}).
    \item \textbf{No Margin ($MAR \to 0$):} The \textit{Fragility Mode}. Persistence requires a safety factor defined by $MAR > k \cdot \sigma_{env}$, where $\sigma_{env}$ represents the variance of environmental fluctuations. A system at theoretical criticality ($MAR \to 0$) survives only in a perfectly static environment. In any real-world substrate, the first non-zero fluctuation pushes the system state outside its basin of attraction, resulting in immediate failure ($\tau \to \text{Random Variable}$).
\end{itemize}

Since the removal of any component results in termination, the set $\mathbb{P}$ is \textbf{Minimally Necessary}.

To demonstrate sufficiency, we note that any stable control system requires exactly these components. Control theory provides no additional fundamental requirements beyond Plant, Setpoint, Feedback, Stability, Latency, and Margin. Any proposed seventh pillar would necessarily decompose into combinations of these six primitive functions.

\textit{Note on Sufficiency:} Complex cognitive functions often cited in systems theory, such as \textbf{Memory} or \textbf{Prediction}, are not distinct pillars but emergent properties of this fundamental set. Memory is the persistence of the Map ($MAP$) over time ($TOL$). Prediction is the operation of the MAP ($MAP$) via the Protocol ($PRO$). Thus, the six pillars constitute the irreducible basis set.

\subsection{Note on Systemic State: Quiescent Equilibrium}
Informational Energetics describes the lifecycle of systems through phases of Genesis, Expansion, Stasis, and Collapse via the mathematics of Logistic Maps/Bifurcation. It is important to note that the system derived next (the Vacuum requirements, System 0), represents a specific thermodynamic state known as \textbf{Quiescent Equilibrium}.

Unlike biological or economic systems which are in a state of Expansion or Brittle Stasis, the fundamental laws of physics represent a system that has minimized its metabolic drag to the absolute theoretical floor ($S_\Phi \to 0$). The geometric invariants derived are not evolving parameters; they are the \textbf{Fixed Point Attractors} of the vacuum's self-optimization. The vacuum is not ``evolving'' new laws; it is persisting within the optimal solution.

\subsection{The Scope of Informational Energetics}
Informational Energetics makes a specific, falsifiable claim: by restricting the focus from all complex adaptive systems to only those systems that successfully \textbf{persist}, we can move from qualitative description to a predictive, universal science, able to analyze their components, model their lifecycle, predict their stability limits, and apply architectural principles across domains.